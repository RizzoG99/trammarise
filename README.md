# Trammarise ğŸ™ï¸

AI-powered audio transcription and summarization web application with multi-AI provider support and interactive chat capabilities.

## Quick Start âš¡

Get Trammarise running in 3 minutes!

### For Users

1. Visit the deployed app
2. Upload or record audio
3. When processing, you'll be prompted for:
   - Your preferred AI provider (ChatGPT, Claude, or Deepseek)
   - Your API key (get instructions in-app)

### For Developers

```bash
# Install dependencies
npm install
npm install -g vercel

# Start development server
vercel dev
```

Open [http://localhost:3000](http://localhost:3000)

**Note**: No environment variables needed - users provide API keys via UI

---

## âœ¨ Features

- ğŸ¤ **Record or Upload** audio files
- ğŸŒŠ **Interactive Waveform** visualization
- âœ‚ï¸ **Audio Trimming** - Select specific portions to process
- ğŸ¤– **AI Transcription** - OpenAI Whisper speech-to-text
- ğŸ”‘ **Choose Your AI** - Select between ChatGPT, Claude, or Deepseek
- ğŸ“ **Smart Summarization** - Context-aware AI summaries
- ğŸ’¬ **Interactive Chat** - Refine summaries, ask questions, translate
- ğŸ”Š **Text-to-Speech** - Read transcripts and summaries aloud
- ğŸ“‹ **Copy to Clipboard** - Easy sharing

### User Flow

```mermaid
graph LR
    A[Start] -->|Upload/Record| B[Audio Editor]
    B -->|Trim/Preview| C[Configuration]
    C -->|Select AI & Keys| D[Processing]
    D -->|Transcribe & Summarize| E[Results]
    E -->|Chat/Export| F[Finish]
```

## ğŸ“‹ Requirements & Specifications

For a detailed breakdown of functional requirements, user stories, and technical specifications, please see our [Functional Analysis](docs/functional-analysis/functional-analysis.md).

## ğŸš€ Tech Stack

- **React 19** - UI library
- **TypeScript** - Type safety
- **Vite** - Build tool and dev server
- **WaveSurfer.js** - Audio waveform visualization
- **OpenAI Whisper** - Universal transcription service
- **Multi-AI Support**:
  - ChatGPT (GPT-4)
  - Claude (3.5 Sonnet)
  - Deepseek
- **Vercel Serverless** - Secure API endpoints
- **React Markdown** - Formatted summary rendering

---

## ğŸ’¡ Usage

### 1. Upload or Record Audio

Click "Start Recording" to record directly, or upload an audio file (MP3, WAV, WEBM, etc.)

### 2. Visualize and Edit

- View your audio as an interactive waveform
- Trim unwanted sections (click scissors icon, drag to select region)

### 3. Click "Process Audio"

### 4. Configure AI Settings

You'll be prompted to:

- Select **content type** (Meeting, Lecture, Interview, Podcast, Voice Memo, or Other)
- Choose **AI provider** (ChatGPT, Claude, or Deepseek)
- Enter your **API key(s)**
  - OpenAI key required for transcription (Whisper)
  - Provider key for summarization
- Click the help section for instructions on getting API keys

### 5. Wait for Processing

- **Transcription**: OpenAI Whisper converts speech to text
- **Summarization**: Your selected AI generates a structured summary

### 6. View Results

- Full transcript
- AI-generated summary with markdown formatting
- Interactive chat interface

### 7. Interactive Chat Examples

- "Make this summary shorter"
- "What are the main action items?"
- "Translate to Spanish"
- "Extract key dates and deadlines"

---

## ğŸ”‘ Getting API Keys

### OpenAI (Required for Transcription)

**Purpose**: Whisper transcription service (used by all providers)

1. Go to [https://platform.openai.com/api-keys](https://platform.openai.com/api-keys)
2. Click "Create new secret key"
3. Copy the key (starts with `sk-`)

**Cost**: ~$0.006 per minute of audio

**Note**: If using ChatGPT for summarization, this same key handles both transcription and summarization.

### ChatGPT (OpenAI GPT-4)

**Purpose**: Summarization and chat

- Uses the same OpenAI key from above
- **Model**: GPT-4
- **Cost**: ~$0.01-0.03 per summary, ~$0.01-0.02 per chat message

### Claude (Anthropic)

**Purpose**: Summarization and chat

1. Go to [https://console.anthropic.com/](https://console.anthropic.com/)
2. Create an account
3. Navigate to API Keys
4. Create a new key

- **Model**: Claude 3.5 Sonnet
- **Cost**: ~$3/$15 per million input/output tokens
- **Note**: Still requires OpenAI key for transcription

### Deepseek

**Purpose**: Summarization and chat (lower cost alternative)

1. Go to [https://platform.deepseek.com/](https://platform.deepseek.com/)
2. Create an account
3. Get your API key

- **Model**: Deepseek-chat
- **Cost**: Lower cost option (check platform for current rates)
- **Note**: Still requires OpenAI key for transcription

### Security Note

- Keys are stored only in your browser's sessionStorage
- Automatically cleared when you close the tab
- Never saved to disk or cloud
- Never exposed to our servers
- **Recommendation**: Set spending limits on your API keys for safety

---

## ğŸ‘¨â€ğŸ’» For Developers

### Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd trammarise

# Install dependencies
npm install

# Install Vercel CLI (required for API routes)
npm install -g vercel

# Start development server
vercel dev
```

The app will be available at `http://localhost:3000`

### Architecture

**Provider Abstraction Pattern** - Multi-AI support using the Strategy Pattern:

```
api/providers/
â”œâ”€â”€ base.ts         # AIProvider interface
â”œâ”€â”€ factory.ts      # Provider factory
â”œâ”€â”€ openai.ts       # ChatGPT (GPT-4) implementation
â”œâ”€â”€ claude.ts       # Claude (3.5 Sonnet) implementation
â””â”€â”€ deepseek.ts     # Deepseek implementation
```

**Key Interface**:

```typescript
export interface AIProvider {
  name: string;
  summarize(params: SummarizeParams): Promise<string>;
  chat(params: ChatParams): Promise<string>;
  validateApiKey(apiKey: string): Promise<boolean>;
}
```

### Project Structure

```
trammarise/
â”œâ”€â”€ api/                          # Vercel serverless functions
â”‚   â”œâ”€â”€ providers/               # AI provider implementations
â”‚   â”‚   â”œâ”€â”€ base.ts             # Provider interface
â”‚   â”‚   â”œâ”€â”€ factory.ts          # Provider factory
â”‚   â”‚   â”œâ”€â”€ openai.ts           # GPT-4 provider
â”‚   â”‚   â”œâ”€â”€ claude.ts           # Claude provider
â”‚   â”‚   â””â”€â”€ deepseek.ts         # Deepseek provider
â”‚   â”œâ”€â”€ transcribe.ts           # Whisper transcription endpoint
â”‚   â”œâ”€â”€ summarize.ts            # AI summarization endpoint
â”‚   â”œâ”€â”€ chat.ts                 # Interactive chat endpoint
â”‚   â””â”€â”€ validate-key.ts         # API key validation
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”œâ”€â”€ states/             # Main app states
â”‚   â”‚   â”‚   â”œâ”€â”€ InitialState.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ RecordingState.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ AudioState.tsx
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfigurationState.tsx  # AI provider selection
â”‚   â”‚   â”‚   â”œâ”€â”€ ProcessingState.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ResultsState.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ forms/              # Form components
â”‚   â”‚   â”‚   â”œâ”€â”€ ConfigurationForm.tsx   # AI config form
â”‚   â”‚   â”‚   â””â”€â”€ ApiKeyInfo.tsx          # API key help
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ audio/              # Audio components
â”‚   â”‚   â”‚   â”œâ”€â”€ WaveformPlayer.tsx
â”‚   â”‚   â”‚   â””â”€â”€ PlaybackControls.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ results/            # Results UI
â”‚   â”‚   â”‚   â”œâ”€â”€ ActionButtons.tsx
â”‚   â”‚   â”‚   â””â”€â”€ ChatInterface.tsx
â”‚   â”‚   â”‚
â”‚   â”‚   â”œâ”€â”€ icons/              # SVG icons
â”‚   â”‚   â””â”€â”€ ui/                 # Reusable UI
â”‚   â”‚       â”œâ”€â”€ Button.tsx
â”‚   â”‚       â””â”€â”€ LoadingSpinner.tsx
â”‚   â”‚
â”‚   â”œâ”€â”€ hooks/                  # Custom React hooks
â”‚   â”‚   â”œâ”€â”€ useAudioRecorder.ts
â”‚   â”‚   â”œâ”€â”€ useWaveSurfer.ts
â”‚   â”‚   â””â”€â”€ useSpeechSynthesis.ts
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                  # Utility functions
â”‚   â”‚   â”œâ”€â”€ api.ts              # API client
â”‚   â”‚   â”œâ”€â”€ audio.ts            # Audio utilities
â”‚   â”‚   â””â”€â”€ session-storage.ts  # API key storage
â”‚   â”‚
â”‚   â””â”€â”€ types/                  # TypeScript types
â”‚       â””â”€â”€ audio.ts
â”‚
â”œâ”€â”€ docs/                       # Developer documentation
â”‚   â””â”€â”€ agent-workflow.md       # Internal development workflow
â”‚
â”œâ”€â”€ .env.example                # Environment template (optional)
â”œâ”€â”€ vercel.json                 # Vercel configuration
â””â”€â”€ package.json                # Dependencies
```

### Available Commands

```bash
vercel dev          # Start dev server with API routes (recommended)
npm run dev         # Start Vite dev server only (no API routes)
npm run build       # Build for production
npm run preview     # Preview production build
npm run lint        # Run ESLint
```

### Contributing

For internal development workflows and agent-based development patterns, see [docs/agent-workflow.md](docs/agent-workflow.md).

---

## ğŸš¢ Deployment

### Deploy to Vercel (Recommended)

1. Push your code to GitHub
2. Import repository in [Vercel Dashboard](https://vercel.com)
3. Deploy!

**No environment variables needed** - users provide their own API keys through the application UI.

### Manual Deployment

```bash
vercel --prod
```

That's it! No configuration required.

---

## ğŸ’° Cost Estimation

Based on current API pricing (as of 2025):

### OpenAI (ChatGPT)

- **Whisper**: ~$0.006/minute
- **GPT-4**: ~$0.01-0.03/summary
- **Chat**: ~$0.01-0.02/message
- **Total for 5min audio**: ~$0.04-0.08

### Claude (Anthropic)

- **Whisper** (OpenAI): ~$0.006/minute
- **Claude 3.5 Sonnet**: ~$3/$15 per million input/output tokens
- **Total for 5min audio**: ~$0.03-0.06

### Deepseek

- **Whisper** (OpenAI): ~$0.006/minute
- **Deepseek-chat**: Lower cost alternative
- Check [platform.deepseek.com](https://platform.deepseek.com/) for current rates

You control your own spending - set API spending limits for safety!

---

## ğŸ”’ Security

- âœ… **API keys stored in browser sessionStorage only**
- âœ… **Automatically cleared when tab closes**
- âœ… **Never saved to disk or cloud**
- âœ… **Never sent to our servers** (only to AI provider APIs)
- âœ… **You control your own API spending limits**
- âš ï¸ **Recommendation**: Set spending limits on your API keys

### For Users

Your API keys are secure and temporary. They:

- Only exist in your browser session
- Are cleared when you close the tab
- Go directly from your browser to the AI provider
- Are never logged or stored by us

### For Developers

Security best practices implemented:

- sessionStorage (not localStorage) for session-only storage
- No API keys in source code or environment variables
- CORS properly configured
- API keys never echoed in responses or logs
- Request timeouts implemented

---

## ğŸ› Troubleshooting

### API Routes Return 404

**Problem**: `/api/*` endpoints not found

**Solution**: Use `vercel dev` instead of `npm run dev`. The Vercel CLI is required to run serverless functions locally.

### Transcription Fails

**Problem**: "Transcription failed" error

**Solutions**:

1. Verify your OpenAI API key is correct
2. Check OpenAI API quota and billing at [platform.openai.com](https://platform.openai.com/)
3. Ensure audio format is supported (webm, mp3, wav, etc.)
4. Check audio file isn't too large (limit: 25MB)

### Summarization Fails

**Problem**: "Summarization failed" after successful transcription

**Solutions**:

1. Verify you entered the correct API key for your chosen provider
2. Check your API provider account has credits/quota
3. Try a different AI provider

### Chat Not Working

**Problem**: Chat messages fail to send

**Solutions**:

1. Verify API key is valid
2. Check API provider account credits
3. Check browser console for specific errors

### API Key Validation Fails

**Problem**: "Invalid API key" message

**Solutions**:

1. Double-check you copied the entire key
2. Ensure no extra spaces before/after the key
3. Verify key is from the correct provider
4. Check key hasn't been revoked or expired
5. Try generating a new key

---

## ğŸ“š Documentation

- [OpenAI API Docs](https://platform.openai.com/docs)
- [Anthropic API Docs](https://docs.anthropic.com/)
- [Deepseek Platform](https://platform.deepseek.com/)
- [Vercel Docs](https://vercel.com/docs)
- [WaveSurfer.js Docs](https://wavesurfer.xyz)
- [React Docs](https://react.dev)

---

## ğŸ“„ License

MIT

---

Built with â¤ï¸ using React, TypeScript, and Multi-AI Providers

## React Compiler

The React Compiler is not enabled on this template because of its impact on dev & build performances. To add it, see [this documentation](https://react.dev/learn/react-compiler/installation).

## Expanding the ESLint Configuration

If you are developing a production application, we recommend updating the configuration to enable type-aware lint rules:

```js
export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      // Other configs...

      // Remove tseslint.configs.recommended and replace with this
      tseslint.configs.recommendedTypeChecked,
      // Alternatively, use this for stricter rules
      tseslint.configs.strictTypeChecked,
      // Optionally, add this for stylistic rules
      tseslint.configs.stylisticTypeChecked,

      // Other configs...
    ],
    languageOptions: {
      parserOptions: {
        project: ['./tsconfig.node.json', './tsconfig.app.json'],
        tsconfigRootDir: import.meta.dirname,
      },
      // other options...
    },
  },
]);
```

You can also install [eslint-plugin-react-x](https://github.com/Rel1cx/eslint-react/tree/main/packages/plugins/eslint-plugin-react-x) and [eslint-plugin-react-dom](https://github.com/Rel1cx/eslint-react/tree/main/packages/plugins/eslint-plugin-react-dom) for React-specific lint rules:

```js
// eslint.config.js
import reactX from 'eslint-plugin-react-x';
import reactDom from 'eslint-plugin-react-dom';

export default defineConfig([
  globalIgnores(['dist']),
  {
    files: ['**/*.{ts,tsx}'],
    extends: [
      // Other configs...
      // Enable lint rules for React
      reactX.configs['recommended-typescript'],
      // Enable lint rules for React DOM
      reactDom.configs.recommended,
    ],
    languageOptions: {
      parserOptions: {
        project: ['./tsconfig.node.json', './tsconfig.app.json'],
        tsconfigRootDir: import.meta.dirname,
      },
      // other options...
    },
  },
]);
```
